{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd490e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "# !pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x  # Colab only.\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
    "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
    "\n",
    "\n",
    "TensorFlow 2.x selected.\n",
    "2.1.0-rc1\n",
    "# additional imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "# Load in the data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
    "32768/29515 [=================================] - 0s 0us/step\n",
    "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
    "26427392/26421880 [==============================] - 0s 0us/step\n",
    "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
    "8192/5148 [===============================================] - 0s 0us/step\n",
    "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
    "4423680/4422102 [==============================] - 0s 0us/step\n",
    "x_train.shape: (60000, 28, 28)\n",
    "# the data is only 2D!\n",
    "# convolution expects height x width x color\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(x_train.shape)\n",
    "(60000, 28, 28, 1)\n",
    "# number of classes\n",
    "K = len(set(y_train))\n",
    "print(\"number of classes:\", K)\n",
    "number of classes: 10\n",
    "# Build the model using the functional API\n",
    "i = Input(shape=x_train[0].shape)\n",
    "x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n",
    "x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)\n",
    "x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(K, activation='softmax')(x)\n",
    "\n",
    "model = Model(i, x)\n",
    "# Compile and fit\n",
    "# Note: make sure you are using the GPU for this!\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15)\n",
    "Train on 60000 samples, validate on 10000 samples\n",
    "Epoch 1/15\n",
    "60000/60000 [==============================] - 11s 175us/sample - loss: 0.5238 - accuracy: 0.8055 - val_loss: 0.3963 - val_accuracy: 0.8485\n",
    "Epoch 2/15\n",
    "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3679 - accuracy: 0.8616 - val_loss: 0.3406 - val_accuracy: 0.8744\n",
    "Epoch 3/15\n",
    "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3158 - accuracy: 0.8802 - val_loss: 0.3336 - val_accuracy: 0.8733\n",
    "Epoch 4/15\n",
    "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2813 - accuracy: 0.8942 - val_loss: 0.3047 - val_accuracy: 0.8878\n",
    "Epoch 5/15\n",
    "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2563 - accuracy: 0.9026 - val_loss: 0.3044 - val_accuracy: 0.8916\n",
    "Epoch 6/15\n",
    "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2363 - accuracy: 0.9104 - val_loss: 0.2950 - val_accuracy: 0.8955\n",
    "Epoch 7/15\n",
    "60000/60000 [==============================] - 7s 108us/sample - loss: 0.2166 - accuracy: 0.9181 - val_loss: 0.2928 - val_accuracy: 0.8985\n",
    "Epoch 8/15\n",
    "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1986 - accuracy: 0.9243 - val_loss: 0.2932 - val_accuracy: 0.9001\n",
    "Epoch 9/15\n",
    "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1863 - accuracy: 0.9294 - val_loss: 0.3185 - val_accuracy: 0.8923\n",
    "Epoch 10/15\n",
    "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1712 - accuracy: 0.9355 - val_loss: 0.3151 - val_accuracy: 0.8970\n",
    "Epoch 11/15\n",
    "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1582 - accuracy: 0.9398 - val_loss: 0.3154 - val_accuracy: 0.8998\n",
    "Epoch 12/15\n",
    "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1509 - accuracy: 0.9414 - val_loss: 0.3235 - val_accuracy: 0.8979\n",
    "Epoch 13/15\n",
    "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1412 - accuracy: 0.9461 - val_loss: 0.3347 - val_accuracy: 0.9013\n",
    "Epoch 14/15\n",
    "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1326 - accuracy: 0.9489 - val_loss: 0.3652 - val_accuracy: 0.8961\n",
    "Epoch 15/15\n",
    "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1266 - accuracy: 0.9520 - val_loss: 0.3516 - val_accuracy: 0.9001\n",
    "# Plot loss per iteration\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "<matplotlib.legend.Legend at 0x7f23402c8860>\n",
    "\n",
    "# Plot accuracy per iteration\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "<matplotlib.legend.Legend at 0x7f23243183c8>\n",
    "\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "  \"\"\"\n",
    "  This function prints and plots the confusion matrix.\n",
    "  Normalization can be applied by setting `normalize=True`.\n",
    "  \"\"\"\n",
    "  if normalize:\n",
    "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "      print(\"Normalized confusion matrix\")\n",
    "  else:\n",
    "      print('Confusion matrix, without normalization')\n",
    "\n",
    "  print(cm)\n",
    "\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt),\n",
    "               horizontalalignment=\"center\",\n",
    "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "p_test = model.predict(x_test).argmax(axis=1)\n",
    "cm = confusion_matrix(y_test, p_test)\n",
    "plot_confusion_matrix(cm, list(range(10)))\n",
    "Confusion matrix, without normalization\n",
    "[[858   0  27  15   3   1  91   0   5   0]\n",
    " [  1 975   2  14   3   0   3   0   2   0]\n",
    " [ 13   1 881  12  51   0  41   0   1   0]\n",
    " [ 12   6  20 887  53   1  20   0   1   0]\n",
    " [  0   1  74  10 875   0  38   0   2   0]\n",
    " [  0   0   1   0   0 977   0  12   1   9]\n",
    " [115   0  87  26 123   0 641   0   8   0]\n",
    " [  0   0   0   0   0  10   0 962   0  28]\n",
    " [  1   0   4   2   8   1   5   2 975   2]\n",
    " [  0   0   0   0   0   4   1  25   0 970]]\n",
    "\n",
    "# Label mapping\n",
    "labels = '''T-shirt/top\n",
    "Trouser\n",
    "Pullover\n",
    "Dress\n",
    "Coat\n",
    "Sandal\n",
    "Shirt\n",
    "Sneaker\n",
    "Bag\n",
    "Ankle boot'''.split(\"\\n\")\n",
    "# Show some misclassified examples\n",
    "misclassified_idx = np.where(p_test != y_test)[0]\n",
    "i = np.random.choice(misclassified_idx)\n",
    "plt.imshow(x_test[i].reshape(28,28), cmap='gray')\n",
    "plt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[p_test[i]]));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "# !pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x  # Colab only.\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "2.0.0-beta1\n",
    "# additional imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "# Load in the data\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "x_train.shape: (50000, 32, 32, 3)\n",
    "y_train.shape (50000,)\n",
    "# number of classes\n",
    "K = len(set(y_train))\n",
    "print(\"number of classes:\", K)\n",
    "number of classes: 10\n",
    "# Build the model using the functional API\n",
    "i = Input(shape=x_train[0].shape)\n",
    "x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n",
    "x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)\n",
    "x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(K, activation='softmax')(x)\n",
    "\n",
    "model = Model(i, x)\n",
    "# Compile and fit\n",
    "# Note: make sure you are using the GPU for this!\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15)\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/15\n",
    "50000/50000 [==============================] - 17s 336us/sample - loss: 1.5736 - accuracy: 0.4255 - val_loss: 1.3048 - val_accuracy: 0.5317\n",
    "Epoch 2/15\n",
    "50000/50000 [==============================] - 16s 320us/sample - loss: 1.2732 - accuracy: 0.5435 - val_loss: 1.1139 - val_accuracy: 0.6004\n",
    "Epoch 3/15\n",
    "50000/50000 [==============================] - 16s 321us/sample - loss: 1.1454 - accuracy: 0.5909 - val_loss: 1.0765 - val_accuracy: 0.6176\n",
    "Epoch 4/15\n",
    "50000/50000 [==============================] - 16s 325us/sample - loss: 1.0497 - accuracy: 0.6259 - val_loss: 0.9637 - val_accuracy: 0.6603\n",
    "Epoch 5/15\n",
    "50000/50000 [==============================] - 16s 325us/sample - loss: 0.9764 - accuracy: 0.6546 - val_loss: 0.9363 - val_accuracy: 0.6728\n",
    "Epoch 6/15\n",
    "50000/50000 [==============================] - 16s 323us/sample - loss: 0.9164 - accuracy: 0.6735 - val_loss: 0.9153 - val_accuracy: 0.6772\n",
    "Epoch 7/15\n",
    "50000/50000 [==============================] - 16s 322us/sample - loss: 0.8660 - accuracy: 0.6944 - val_loss: 0.8996 - val_accuracy: 0.6818\n",
    "Epoch 8/15\n",
    "50000/50000 [==============================] - 17s 330us/sample - loss: 0.8213 - accuracy: 0.7083 - val_loss: 0.8806 - val_accuracy: 0.6954\n",
    "Epoch 9/15\n",
    "50000/50000 [==============================] - 16s 328us/sample - loss: 0.7807 - accuracy: 0.7233 - val_loss: 0.8833 - val_accuracy: 0.6951\n",
    "Epoch 10/15\n",
    "50000/50000 [==============================] - 16s 327us/sample - loss: 0.7470 - accuracy: 0.7359 - val_loss: 0.8368 - val_accuracy: 0.7058\n",
    "Epoch 11/15\n",
    "50000/50000 [==============================] - 16s 325us/sample - loss: 0.7121 - accuracy: 0.7462 - val_loss: 0.8376 - val_accuracy: 0.7092\n",
    "Epoch 12/15\n",
    "50000/50000 [==============================] - 17s 330us/sample - loss: 0.6808 - accuracy: 0.7560 - val_loss: 0.8430 - val_accuracy: 0.7115\n",
    "Epoch 13/15\n",
    "50000/50000 [==============================] - 16s 328us/sample - loss: 0.6576 - accuracy: 0.7671 - val_loss: 0.8284 - val_accuracy: 0.7110\n",
    "Epoch 14/15\n",
    "50000/50000 [==============================] - 16s 328us/sample - loss: 0.6402 - accuracy: 0.7702 - val_loss: 0.8487 - val_accuracy: 0.7067\n",
    "Epoch 15/15\n",
    "50000/50000 [==============================] - 16s 328us/sample - loss: 0.6232 - accuracy: 0.7769 - val_loss: 0.8320 - val_accuracy: 0.7136\n",
    "# Plot loss per iteration\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "<matplotlib.legend.Legend at 0x7f04d6f0db00>\n",
    "\n",
    "# Plot accuracy per iteration\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "<matplotlib.legend.Legend at 0x7f04d6b34208>\n",
    "\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "  \"\"\"\n",
    "  This function prints and plots the confusion matrix.\n",
    "  Normalization can be applied by setting `normalize=True`.\n",
    "  \"\"\"\n",
    "  if normalize:\n",
    "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "      print(\"Normalized confusion matrix\")\n",
    "  else:\n",
    "      print('Confusion matrix, without normalization')\n",
    "\n",
    "  print(cm)\n",
    "\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt),\n",
    "               horizontalalignment=\"center\",\n",
    "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "p_test = model.predict(x_test).argmax(axis=1)\n",
    "cm = confusion_matrix(y_test, p_test)\n",
    "plot_confusion_matrix(cm, list(range(10)))\n",
    "Confusion matrix, without normalization\n",
    "[[741  16  36  26  12   2   6  11 113  37]\n",
    " [ 14 781   9   9   2   4   6   2  47 126]\n",
    " [ 62   9 545  91 102  66  50  29  28  18]\n",
    " [ 20   9  51 548  51 171  58  33  30  29]\n",
    " [ 40  10  62  79 617  43  47  78  19   5]\n",
    " [ 15   2  52 214  38 572  13  55  21  18]\n",
    " [  6   9  45 101  43  44 711   7  18  16]\n",
    " [ 24   3  38  48  59  64   5 726   6  27]\n",
    " [ 49  30   9  17   6   3   1   3 865  17]\n",
    " [ 35 105  16  19   4   7   1  11  46 756]]\n",
    "\n",
    "# label mapping\n",
    "labels = '''airplane\n",
    "automobile\n",
    "bird\n",
    "cat\n",
    "deer\n",
    "dog\n",
    "frog\n",
    "horse\n",
    "ship\n",
    "truck'''.split()\n",
    "# Show some misclassified examples\n",
    "# TODO: add label names\n",
    "misclassified_idx = np.where(p_test != y_test)[0]\n",
    "i = np.random.choice(misclassified_idx)\n",
    "plt.imshow(x_test[i], cmap='gray')\n",
    "plt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[p_test[i]]));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d52033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "# !pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x  # Colab only.\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
    "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
    "\n",
    "\n",
    "TensorFlow 2.x selected.\n",
    "2.2.0-rc2\n",
    "# additional imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "# Load in the data\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "170500096/170498071 [==============================] - 13s 0us/step\n",
    "x_train.shape: (50000, 32, 32, 3)\n",
    "y_train.shape (50000,)\n",
    "# number of classes\n",
    "K = len(set(y_train))\n",
    "print(\"number of classes:\", K)\n",
    "number of classes: 10\n",
    "# Build the model using the functional API\n",
    "i = Input(shape=x_train[0].shape)\n",
    "# x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)\n",
    "# x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)\n",
    "# x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "\n",
    "# x = GlobalMaxPooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(K, activation='softmax')(x)\n",
    "\n",
    "model = Model(i, x)\n",
    "# Compile\n",
    "# Note: make sure you are using the GPU for this!\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Fit\n",
    "r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50)\n",
    "Epoch 1/50\n",
    "1465/1563 [===========================>..] - ETA: 0s - loss: 1.2974 - accuracy: 0.5487\n",
    "---------------------------------------------------------------------------\n",
    "KeyboardInterrupt                         Traceback (most recent call last)\n",
    "<ipython-input-7-8848f77f4588> in <module>()\n",
    "----> 1 r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50)\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\n",
    "     64   def _method_wrapper(self, *args, **kwargs):\n",
    "     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\n",
    "---> 66       return method(self, *args, **kwargs)\n",
    "     67 \n",
    "     68     # Running inside `run_distribute_coordinator` already.\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\n",
    "    790                 context.async_wait()\n",
    "    791               logs = tmp_logs  # No error, now safe to assign to logs.\n",
    "--> 792               callbacks.on_train_batch_end(step, logs)\n",
    "    793         epoch_logs = copy.copy(logs)\n",
    "    794 \n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)\n",
    "    387     \"\"\"\n",
    "    388     if self._should_call_train_batch_hooks:\n",
    "--> 389       logs = self._process_logs(logs)\n",
    "    390       self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)\n",
    "    391 \n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _process_logs(self, logs)\n",
    "    263     \"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\n",
    "    264     if logs:\n",
    "--> 265       return tf_utils.to_numpy_or_python_type(logs)\n",
    "    266     return {}\n",
    "    267 \n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in to_numpy_or_python_type(tensors)\n",
    "    521     return t  # Don't turn ragged or sparse tensors to NumPy.\n",
    "    522 \n",
    "--> 523   return nest.map_structure(_to_single_numpy_or_python_type, tensors)\n",
    "    524 \n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)\n",
    "    615 \n",
    "    616   return pack_sequence_as(\n",
    "--> 617       structure[0], [func(*x) for x in entries],\n",
    "    618       expand_composites=expand_composites)\n",
    "    619 \n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in <listcomp>(.0)\n",
    "    615 \n",
    "    616   return pack_sequence_as(\n",
    "--> 617       structure[0], [func(*x) for x in entries],\n",
    "    618       expand_composites=expand_composites)\n",
    "    619 \n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in _to_single_numpy_or_python_type(t)\n",
    "    517   def _to_single_numpy_or_python_type(t):\n",
    "    518     if isinstance(t, ops.Tensor):\n",
    "--> 519       x = t.numpy()\n",
    "    520       return x.item() if np.ndim(x) == 0 else x\n",
    "    521     return t  # Don't turn ragged or sparse tensors to NumPy.\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in numpy(self)\n",
    "    959     \"\"\"\n",
    "    960     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\n",
    "--> 961     maybe_arr = self._numpy()  # pylint: disable=protected-access\n",
    "    962     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr\n",
    "    963 \n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _numpy(self)\n",
    "    925     # pylint: disable=protected-access\n",
    "    926     try:\n",
    "--> 927       return self._numpy_internal()\n",
    "    928     except core._NotOkStatusException as e:\n",
    "    929       six.raise_from(core._status_to_exception(e.code, e.message), None)\n",
    "\n",
    "KeyboardInterrupt: \n",
    "# Fit with data augmentation\n",
    "# Note: if you run this AFTER calling the previous model.fit(), it will CONTINUE training where it left off\n",
    "batch_size = 32\n",
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "train_generator = data_generator.flow(x_train, y_train, batch_size)\n",
    "steps_per_epoch = x_train.shape[0] // batch_size\n",
    "r = model.fit(train_generator, validation_data=(x_test, y_test), steps_per_epoch=steps_per_epoch, epochs=50)\n",
    "Epoch 1/50\n",
    "1562/1562 [==============================] - 27s 17ms/step - loss: 0.9854 - accuracy: 0.6597 - val_loss: 0.9380 - val_accuracy: 0.6898\n",
    "Epoch 2/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.8444 - accuracy: 0.7101 - val_loss: 0.8461 - val_accuracy: 0.7158\n",
    "Epoch 3/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.7506 - accuracy: 0.7444 - val_loss: 0.7562 - val_accuracy: 0.7485\n",
    "Epoch 4/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.6825 - accuracy: 0.7695 - val_loss: 0.6062 - val_accuracy: 0.7959\n",
    "Epoch 5/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.6324 - accuracy: 0.7856 - val_loss: 0.6161 - val_accuracy: 0.7971\n",
    "Epoch 6/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.5944 - accuracy: 0.7997 - val_loss: 0.6473 - val_accuracy: 0.7832\n",
    "Epoch 7/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.5502 - accuracy: 0.8109 - val_loss: 0.6116 - val_accuracy: 0.8007\n",
    "Epoch 8/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.5210 - accuracy: 0.8227 - val_loss: 0.6694 - val_accuracy: 0.7861\n",
    "Epoch 9/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.4947 - accuracy: 0.8300 - val_loss: 0.4850 - val_accuracy: 0.8358\n",
    "Epoch 10/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.4690 - accuracy: 0.8407 - val_loss: 0.5492 - val_accuracy: 0.8174\n",
    "Epoch 11/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.4480 - accuracy: 0.8479 - val_loss: 0.5357 - val_accuracy: 0.8212\n",
    "Epoch 12/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.4283 - accuracy: 0.8523 - val_loss: 0.5085 - val_accuracy: 0.8319\n",
    "Epoch 13/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.4125 - accuracy: 0.8577 - val_loss: 0.5201 - val_accuracy: 0.8308\n",
    "Epoch 14/50\n",
    "1562/1562 [==============================] - 26s 16ms/step - loss: 0.3929 - accuracy: 0.8662 - val_loss: 0.4446 - val_accuracy: 0.8510\n",
    "Epoch 15/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.3779 - accuracy: 0.8694 - val_loss: 0.4738 - val_accuracy: 0.8506\n",
    "Epoch 16/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.3706 - accuracy: 0.8721 - val_loss: 0.4617 - val_accuracy: 0.8504\n",
    "Epoch 17/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.3470 - accuracy: 0.8812 - val_loss: 0.4172 - val_accuracy: 0.8627\n",
    "Epoch 18/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.3405 - accuracy: 0.8818 - val_loss: 0.4572 - val_accuracy: 0.8587\n",
    "Epoch 19/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.3312 - accuracy: 0.8868 - val_loss: 0.4150 - val_accuracy: 0.8654\n",
    "Epoch 20/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.3203 - accuracy: 0.8880 - val_loss: 0.5443 - val_accuracy: 0.8273\n",
    "Epoch 21/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.3108 - accuracy: 0.8919 - val_loss: 0.4421 - val_accuracy: 0.8605\n",
    "Epoch 22/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.3017 - accuracy: 0.8964 - val_loss: 0.4778 - val_accuracy: 0.8537\n",
    "Epoch 23/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2978 - accuracy: 0.8975 - val_loss: 0.4370 - val_accuracy: 0.8621\n",
    "Epoch 24/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2830 - accuracy: 0.9023 - val_loss: 0.4270 - val_accuracy: 0.8676\n",
    "Epoch 25/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2796 - accuracy: 0.9035 - val_loss: 0.4009 - val_accuracy: 0.8748\n",
    "Epoch 26/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2714 - accuracy: 0.9069 - val_loss: 0.4017 - val_accuracy: 0.8719\n",
    "Epoch 27/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2663 - accuracy: 0.9080 - val_loss: 0.4199 - val_accuracy: 0.8669\n",
    "Epoch 28/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2547 - accuracy: 0.9121 - val_loss: 0.4094 - val_accuracy: 0.8703\n",
    "Epoch 29/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2574 - accuracy: 0.9110 - val_loss: 0.4227 - val_accuracy: 0.8698\n",
    "Epoch 30/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2464 - accuracy: 0.9141 - val_loss: 0.4117 - val_accuracy: 0.8649\n",
    "Epoch 31/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2439 - accuracy: 0.9157 - val_loss: 0.4096 - val_accuracy: 0.8758\n",
    "Epoch 32/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2411 - accuracy: 0.9159 - val_loss: 0.4118 - val_accuracy: 0.8705\n",
    "Epoch 33/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2330 - accuracy: 0.9194 - val_loss: 0.3841 - val_accuracy: 0.8764\n",
    "Epoch 34/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2312 - accuracy: 0.9201 - val_loss: 0.4127 - val_accuracy: 0.8708\n",
    "Epoch 35/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2272 - accuracy: 0.9209 - val_loss: 0.4259 - val_accuracy: 0.8762\n",
    "Epoch 36/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2204 - accuracy: 0.9241 - val_loss: 0.4246 - val_accuracy: 0.8769\n",
    "Epoch 37/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2150 - accuracy: 0.9251 - val_loss: 0.3939 - val_accuracy: 0.8797\n",
    "Epoch 38/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2156 - accuracy: 0.9261 - val_loss: 0.4005 - val_accuracy: 0.8790\n",
    "Epoch 39/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2135 - accuracy: 0.9268 - val_loss: 0.3959 - val_accuracy: 0.8773\n",
    "Epoch 40/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2121 - accuracy: 0.9263 - val_loss: 0.4072 - val_accuracy: 0.8742\n",
    "Epoch 41/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2087 - accuracy: 0.9277 - val_loss: 0.4234 - val_accuracy: 0.8769\n",
    "Epoch 42/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.2023 - accuracy: 0.9310 - val_loss: 0.3904 - val_accuracy: 0.8812\n",
    "Epoch 43/50\n",
    "1562/1562 [==============================] - 26s 16ms/step - loss: 0.1986 - accuracy: 0.9311 - val_loss: 0.3859 - val_accuracy: 0.8806\n",
    "Epoch 44/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.1936 - accuracy: 0.9341 - val_loss: 0.4627 - val_accuracy: 0.8703\n",
    "Epoch 45/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.1907 - accuracy: 0.9342 - val_loss: 0.4460 - val_accuracy: 0.8646\n",
    "Epoch 46/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.1884 - accuracy: 0.9341 - val_loss: 0.4511 - val_accuracy: 0.8658\n",
    "Epoch 47/50\n",
    "1562/1562 [==============================] - 26s 17ms/step - loss: 0.1877 - accuracy: 0.9344 - val_loss: 0.3790 - val_accuracy: 0.8831\n",
    "Epoch 48/50\n",
    "1562/1562 [==============================] - 26s 16ms/step - loss: 0.1851 - accuracy: 0.9366 - val_loss: 0.4208 - val_accuracy: 0.8770\n",
    "Epoch 49/50\n",
    "1562/1562 [==============================] - 26s 16ms/step - loss: 0.1869 - accuracy: 0.9364 - val_loss: 0.3946 - val_accuracy: 0.8841\n",
    "Epoch 50/50\n",
    "1562/1562 [==============================] - 26s 16ms/step - loss: 0.1767 - accuracy: 0.9397 - val_loss: 0.4432 - val_accuracy: 0.8781\n",
    "# Plot loss per iteration\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "<matplotlib.legend.Legend at 0x7f1d5a2856d8>\n",
    "\n",
    "# Plot accuracy per iteration\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "<matplotlib.legend.Legend at 0x7f1d5a26ada0>\n",
    "\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "  \"\"\"\n",
    "  This function prints and plots the confusion matrix.\n",
    "  Normalization can be applied by setting `normalize=True`.\n",
    "  \"\"\"\n",
    "  if normalize:\n",
    "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "      print(\"Normalized confusion matrix\")\n",
    "  else:\n",
    "      print('Confusion matrix, without normalization')\n",
    "\n",
    "  print(cm)\n",
    "\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt),\n",
    "               horizontalalignment=\"center\",\n",
    "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "p_test = model.predict(x_test).argmax(axis=1)\n",
    "cm = confusion_matrix(y_test, p_test)\n",
    "plot_confusion_matrix(cm, list(range(10)))\n",
    "Confusion matrix, without normalization\n",
    "[[908  14  12   2   1   0   2   2  33  26]\n",
    " [  5 957   0   0   0   1   3   0   4  30]\n",
    " [ 42   4 817  18  28  18  43  11   7  12]\n",
    " [ 22  18  27 742  29  62  48  19  13  20]\n",
    " [ 16   2  39  22 847  16  34  15   5   4]\n",
    " [  5  10  22  94  23 790  21  23   4   8]\n",
    " [  4   2  16  18   4   2 946   1   4   3]\n",
    " [ 15   5   6  15  27   6   5 908   6   7]\n",
    " [ 37  12   1   3   0   0   1   2 921  23]\n",
    " [  9  37   0   0   1   1   2   1   4 945]]\n",
    "\n",
    "# label mapping\n",
    "labels = '''airplane\n",
    "automobile\n",
    "bird\n",
    "cat\n",
    "deer\n",
    "dog\n",
    "frog\n",
    "horse\n",
    "ship\n",
    "truck'''.split()\n",
    "# Show some misclassified examples\n",
    "misclassified_idx = np.where(p_test != y_test)[0]\n",
    "i = np.random.choice(misclassified_idx)\n",
    "plt.imshow(x_test[i], cmap='gray')\n",
    "plt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[p_test[i]]));\n",
    "\n",
    "# Now that the model is so large, it's useful to summarize it\n",
    "model.summary()\n",
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
    "_________________________________________________________________\n",
    "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
    "_________________________________________________________________\n",
    "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
    "_________________________________________________________________\n",
    "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
    "_________________________________________________________________\n",
    "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
    "_________________________________________________________________\n",
    "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
    "_________________________________________________________________\n",
    "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
    "_________________________________________________________________\n",
    "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 2048)              0         \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 2048)              0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 1024)              2098176   \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 1024)              0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 10)                10250     \n",
    "=================================================================\n",
    "Total params: 2,397,226\n",
    "Trainable params: 2,396,330\n",
    "Non-trainable params: 896\n",
    "_________________________________________________________________\n",
    "sss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
